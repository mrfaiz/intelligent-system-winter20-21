{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 : Inconsistancy Rate calculation #\n",
    "\n",
    "1. Used status columns from station_a, station_b, station_c and level_cm of station_main\n",
    "2. Used SAX \n",
    "3. used \"level_cm\" of station_main as reference and binning\n",
    "4. Followed Exercise Solution 04\n",
    "5. Applied the IR calculation methodology from the lecture note (chapter 4, slide 75)\n",
    "6. Calculated IR = 0.26477860839562967"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "import string\n",
    "\n",
    "col_time= \"time\"\n",
    "col_temp_c = \"temp_c\"\n",
    "col_status = \"status\"\n",
    "col_rain_mm = \"rain_mm\"\n",
    "col_level_cm = \"level_cm\"\n",
    "col_flow_m2_s = \"flow_m2_s\"\n",
    "\n",
    "statin_a_csv = \"station_a_improved.csv\"\n",
    "statin_b_csv = \"station_b_improved.csv\"\n",
    "statin_c_csv = \"station_c_improved.csv\"\n",
    "station_main_csv = \"station_main_improved.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the SAX (Symbolic Aggregate Approximation) Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAX(object):\n",
    "    \"\"\"\n",
    "    This class is for computing common things with the Symbolic\n",
    "    Aggregate approXimation method.  In short, this translates\n",
    "    a series of data to a string, which can then be compared with other\n",
    "    such strings using a lookup table.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, wordSize = 9, alphabetSize = 10, epsilon = 1e-6):\n",
    "\n",
    "        if alphabetSize < 3 or alphabetSize > 20:\n",
    "            raise DictionarySizeIsNotSupported()\n",
    "        self.aOffset = ord('a')\n",
    "        self.wordSize = wordSize\n",
    "        self.alphabetSize = alphabetSize\n",
    "        self.eps = epsilon\n",
    "        self.breakpoints = {'3' : [-0.43, 0.43],\n",
    "                            '4' : [-0.67, 0, 0.67],\n",
    "                            '5' : [-0.84, -0.25, 0.25, 0.84],\n",
    "                            '6' : [-0.97, -0.43, 0, 0.43, 0.97],\n",
    "                            '7' : [-1.07, -0.57, -0.18, 0.18, 0.57, 1.07],\n",
    "                            '8' : [-1.15, -0.67, -0.32, 0, 0.32, 0.67, 1.15],\n",
    "                            '9' : [-1.22, -0.76, -0.43, -0.14, 0.14, 0.43, 0.76, 1.22],\n",
    "                            '10': [-1.28, -0.84, -0.52, -0.25, 0, 0.25, 0.52, 0.84, 1.28],\n",
    "                            '11': [-1.34, -0.91, -0.6, -0.35, -0.11, 0.11, 0.35, 0.6, 0.91, 1.34],\n",
    "                            '12': [-1.38, -0.97, -0.67, -0.43, -0.21, 0, 0.21, 0.43, 0.67, 0.97, 1.38],\n",
    "                            '13': [-1.43, -1.02, -0.74, -0.5, -0.29, -0.1, 0.1, 0.29, 0.5, 0.74, 1.02, 1.43],\n",
    "                            '14': [-1.47, -1.07, -0.79, -0.57, -0.37, -0.18, 0, 0.18, 0.37, 0.57, 0.79, 1.07, 1.47],\n",
    "                            '15': [-1.5, -1.11, -0.84, -0.62, -0.43, -0.25, -0.08, 0.08, 0.25, 0.43, 0.62, 0.84, 1.11, 1.5],\n",
    "                            '16': [-1.53, -1.15, -0.89, -0.67, -0.49, -0.32, -0.16, 0, 0.16, 0.32, 0.49, 0.67, 0.89, 1.15, 1.53],\n",
    "                            '17': [-1.56, -1.19, -0.93, -0.72, -0.54, -0.38, -0.22, -0.07, 0.07, 0.22, 0.38, 0.54, 0.72, 0.93, 1.19, 1.56],\n",
    "                            '18': [-1.59, -1.22, -0.97, -0.76, -0.59, -0.43, -0.28, -0.14, 0, 0.14, 0.28, 0.43, 0.59, 0.76, 0.97, 1.22, 1.59],\n",
    "                            '19': [-1.62, -1.25, -1, -0.8, -0.63, -0.48, -0.34, -0.2, -0.07, 0.07, 0.2, 0.34, 0.48, 0.63, 0.8, 1, 1.25, 1.62],\n",
    "                            '20': [-1.64, -1.28, -1.04, -0.84, -0.67, -0.52, -0.39, -0.25, -0.13, 0, 0.13, 0.25, 0.39, 0.52, 0.67, 0.84, 1.04, 1.28, 1.64]\n",
    "                            }\n",
    "        self.beta = self.breakpoints[str(self.alphabetSize)]\n",
    "        self.build_letter_compare_dict()\n",
    "        self.scalingFactor = 1\n",
    "\n",
    "\n",
    "    def to_letter_rep(self, x):\n",
    "        \"\"\"\n",
    "        Function takes a series of data, x, and transforms it to a string representation\n",
    "        \"\"\"\n",
    "        (paaX, indices) = self.to_PAA(self.normalize(x))\n",
    "        self.scalingFactor = np.sqrt(len(x) / self.wordSize)\n",
    "        return (self.alphabetize(paaX), indices)\n",
    "\n",
    "    def normalize(self, x):\n",
    "        \"\"\"\n",
    "        Function will normalize an array (give it a mean of 0, and a\n",
    "        standard deviation of 1) unless it's standard deviation is below\n",
    "        epsilon, in which case it returns an array of zeros the length\n",
    "        of the original array.\n",
    "        \"\"\"\n",
    "        X = np.asanyarray(x)\n",
    "        if X.std() < self.eps:\n",
    "            return [0 for entry in X]\n",
    "        return (X-X.mean())/X.std()\n",
    "\n",
    "    def to_PAA(self, x):\n",
    "        \"\"\"\n",
    "        Funciton performs Piecewise Aggregate Approximation on data set, reducing\n",
    "        the dimension of the dataset x to w discrete levels. returns the reduced\n",
    "        dimension data set, as well as the indicies corresponding to the original\n",
    "        data for each reduced dimension\n",
    "        \"\"\"\n",
    "        n = len(x)\n",
    "        stepFloat = n/float(self.wordSize)\n",
    "        step = int(math.ceil(stepFloat))\n",
    "        frameStart = 0\n",
    "        approximation = []\n",
    "        indices = []\n",
    "        i = 0\n",
    "        while frameStart <= n-step:\n",
    "            thisFrame = np.array(x[frameStart:int(frameStart + step)])\n",
    "            approximation.append(np.mean(thisFrame))\n",
    "            indices.append((frameStart, int(frameStart + step)))\n",
    "            i += 1\n",
    "            frameStart = int(i*stepFloat)\n",
    "        return (np.array(approximation), indices)\n",
    "\n",
    "    def alphabetize(self,paaX):\n",
    "        \"\"\"\n",
    "        Converts the Piecewise Aggregate Approximation of x to a series of letters.\n",
    "        \"\"\"\n",
    "        alphabetizedX = ''\n",
    "        for i in range(0, len(paaX)):\n",
    "            letterFound = False\n",
    "            for j in range(0, len(self.beta)):\n",
    "                if paaX[i] < self.beta[j]:\n",
    "                    alphabetizedX += chr(self.aOffset + j)\n",
    "                    letterFound = True\n",
    "                    break\n",
    "            if not letterFound:\n",
    "                alphabetizedX += chr(self.aOffset + len(self.beta))\n",
    "        return alphabetizedX\n",
    "\n",
    "    def compare_strings(self, sA, sB, x=None):\n",
    "        \"\"\"\n",
    "        Compares two strings based on individual letter distance\n",
    "        Requires that both strings are the same length\n",
    "        \"\"\"\n",
    "        \n",
    "        if x != None:\n",
    "            self.scalingFactor = np.sqrt(x / self.wordSize)\n",
    "        \n",
    "        if len(sA) != len(sB):\n",
    "            raise StringsAreDifferentLength()\n",
    "        list_letters_a = [x for x in sA]\n",
    "        list_letters_b = [x for x in sB]\n",
    "        mindist = 0.0\n",
    "        for i in range(0, len(list_letters_a)):\n",
    "            mindist += self.compare_letters(list_letters_a[i], list_letters_b[i])**2\n",
    "        mindist = self.scalingFactor* np.sqrt(mindist)\n",
    "        return mindist\n",
    "\n",
    "    def compare_letters(self, la, lb):\n",
    "        \"\"\"\n",
    "        Compare two letters based on letter distance return distance between\n",
    "        \"\"\"\n",
    "        return self.compareDict[la+lb]\n",
    "\n",
    "    def build_letter_compare_dict(self):\n",
    "        \"\"\"\n",
    "        Builds up the lookup table to determine numeric distance between two letters\n",
    "        given an alphabet size.  Entries for both 'ab' and 'ba' will be created\n",
    "        and will have identical values.\n",
    "        \"\"\"\n",
    "\n",
    "        number_rep = range(0,self.alphabetSize)\n",
    "        letters = [chr(x + self.aOffset) for x in number_rep]\n",
    "        self.compareDict = {}\n",
    "        for i in range(0, len(letters)):\n",
    "            for j in range(0, len(letters)):\n",
    "                if np.abs(number_rep[i]-number_rep[j]) <=1:\n",
    "                    self.compareDict[letters[i]+letters[j]] = 0\n",
    "                else:\n",
    "                    high_num = np.max([number_rep[i], number_rep[j]])-1\n",
    "                    low_num = np.min([number_rep[i], number_rep[j]])\n",
    "                    self.compareDict[letters[i]+letters[j]] = self.beta[high_num] - self.beta[low_num]\n",
    "\n",
    "    def sliding_window(self, x, numSubsequences = None, overlappingFraction = None):\n",
    "        if not numSubsequences:\n",
    "            numSubsequences = 20\n",
    "        self.windowSize = int(len(x)/numSubsequences)\n",
    "        if not overlappingFraction:\n",
    "            overlappingFraction = 0.9\n",
    "        overlap = self.windowSize*overlappingFraction\n",
    "        moveSize = int(self.windowSize - overlap)\n",
    "        if moveSize < 1:\n",
    "            raise OverlapSpecifiedIsNotSmallerThanWindowSize()\n",
    "        ptr = 0\n",
    "        n = len(x)\n",
    "        windowIndices = []\n",
    "        stringRep = []\n",
    "        while ptr < n-self.windowSize+1:\n",
    "            thisSubRange = x[ptr:ptr+self.windowSize]\n",
    "            (thisStringRep,indices) = self.to_letter_rep(thisSubRange)\n",
    "            stringRep.append(thisStringRep)\n",
    "            windowIndices.append((ptr, ptr+self.windowSize))\n",
    "            ptr += moveSize\n",
    "        return (stringRep,windowIndices)\n",
    "    \n",
    "    def batch_compare(self, xStrings, refString):\n",
    "        return [self.compare_strings(x, refString) for x in xStrings]\n",
    "\n",
    "    def set_scaling_factor(self, scalingFactor):\n",
    "        self.scalingFactor = scalingFactor\n",
    "\n",
    "    def set_window_size(self, windowSize):\n",
    "        self.windowSize = windowSize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nothing to do here\n",
    "\n",
    "def plot_SAX(timeSeries, sax):\n",
    "     \n",
    "    \"\"\"Helper Method to plot final result, \n",
    "    requires a dataFrame with columns paa1 and paa2 and a SAX object.\"\"\"\n",
    "\n",
    "    timeSeries.plot(y=[\"paa_a\", \"paa_b\",\"paa_c\"], use_index=True)\n",
    "    alphabet = list(string.ascii_lowercase)\n",
    "    segments = sax.breakpoints[str(sax.alphabetSize)]\n",
    "\n",
    "    for i in range(len(segments)):\n",
    "        plt.axhline(segments[i], color='r', linestyle='--', label=alphabet[i])\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_a = pd.read_csv(statin_a_csv, parse_dates=['time'],index_col='time')\n",
    "station_a.rename(columns={col_temp_c: \"a_temp\", col_status: \"a_status\", col_rain_mm: \"a_rain\" },inplace=True)\n",
    "station_a = station_a.loc[:, ~station_a.columns.str.contains('^Unnamed')]\n",
    "\n",
    "station_b = pd.read_csv(statin_b_csv, parse_dates=[col_time],index_col=col_time)\n",
    "station_b.rename(columns={col_temp_c: \"b_temp\", col_status: \"b_status\", col_rain_mm: \"b_rain\" },inplace=True)\n",
    "station_b = station_b.loc[:, ~station_b.columns.str.contains('^Unnamed')]\n",
    "\n",
    "station_c = pd.read_csv(statin_c_csv, parse_dates=[col_time],index_col=col_time)\n",
    "station_c.rename(columns={col_temp_c: \"c_temp\", col_status: \"c_status\", col_rain_mm: \"c_rain\" },inplace=True)\n",
    "station_c = station_c.loc[:, ~station_c.columns.str.contains('^Unnamed')]\n",
    "\n",
    "station_main = pd.read_csv(station_main_csv, parse_dates=[col_time],index_col=col_time)\n",
    "station_main = station_main.loc[:, ~station_main.columns.str.contains('^Unnamed')]\n",
    "\n",
    "station_main_water_level =  station_main.drop([col_flow_m2_s], axis = 1) \n",
    "station_main_water_level[col_level_cm][station_main_water_level[col_level_cm]<0] = 0\n",
    "\n",
    "merged_sation_a_b = pd.merge(left=station_a, right=station_b, left_on='time', right_on='time')\n",
    "merged_station_a_b_c = pd.merge(left=merged_sation_a_b, right=station_c, left_on='time', right_on='time')\n",
    "\n",
    "status = merged_station_a_b_c.drop(['a_temp', 'a_rain','b_temp', 'b_rain','c_temp', 'c_rain'], axis = 1) \n",
    "\n",
    "status_water_level = pd.merge(left=status, right=station_main_water_level, left_on='time', right_on='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "sax = SAX()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['d', 'e', 'f', 'g', 'h', 'i', 'j'], dtype=object)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standarize_level = \"standarize_level\"\n",
    "col_word_level = \"word_level\"\n",
    "status_water_level[standarize_level] = sax.normalize(status_water_level[col_level_cm])\n",
    "status_water_level[col_word_level] = list(sax.alphabetize(status_water_level[standarize_level].tolist()))\n",
    "# status_water_level.groupby(\"word_level\").count()\n",
    "\n",
    "unique_classes = status_water_level[col_word_level].unique()\n",
    "unique_classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes are ##\n",
    "\n",
    "['d', 'e', 'f', 'g', 'h', 'i', 'j']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fill up data inside according to classes ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For unique tuple\n",
    "samples = set()\n",
    "# Create lookup dictionary for class count for sample.\n",
    "class_dict = {}\n",
    "\n",
    "for index, row in status_water_level.iterrows():\n",
    "    sample = (row[\"a_status\"], row[\"b_status\"], row[\"c_status\"])\n",
    "    class_dict[sample] = np.zeros(len(uniqe_wordBins))\n",
    "\n",
    "# Count occurences of words\n",
    "\n",
    "for index, row in status_water_level.iterrows():\n",
    "    sample = (row[\"a_status\"], row[\"b_status\"], row[\"c_status\"])\n",
    "    try:\n",
    "        value_index = np.where(uniqe_wordBins ==row[col_word_level])\n",
    "        class_dict[sample][value_index] += 1\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate IZs and IR ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26477860839562967"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "izs = [] \n",
    "for sample in class_dict:\n",
    "    iz = np.sum(class_dict[sample]) - np.max(class_dict[sample])\n",
    "    izs.append(iz)\n",
    "\n",
    "IR = sum(izs) / len(status_water_level)\n",
    "IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
