{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_station_a = \"sample_42_station_a.csv\"\n",
    "file_station_c = \"sample_42_station_c.csv\"\n",
    "file_station_main = \"sample_42_station_main.csv\"\n",
    "# file_all_station = \"sample_42_stations.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_a = pd.read_csv(file_station_a, index_col=\"time\", parse_dates=True)\n",
    "station_c = pd.read_csv(file_station_c, index_col=\"time\", parse_dates=True)\n",
    "station_main = pd.read_csv(file_station_main, index_col=\"time\", parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X_y(df):\n",
    "    \"\"\"\n",
    "\tX has the following format:\n",
    "\tOne week per row\n",
    "\trow == sample\n",
    "\t9 sensor values (including timestamps) * 24 h * 7 days = 1512 entries per sample\n",
    "\n",
    "\t[t_0, w_station_A(t_0), w_station_B(t_0), w_station_C(t_0), \n",
    "\t t_1, w_station_A(t_1), w_station_B(t_1), w_station_C(t_1), \n",
    "\t \n",
    "\t t_N, w_station_A(t_N), w_station_B(t_N), w_station_C(t_N)] \n",
    "\n",
    "\n",
    "\t\"\"\"\n",
    "    timestamps = df.shape[0]\n",
    "   \n",
    "    prediction_timestamps = 24\n",
    "    prediction_step = 3\n",
    "    \n",
    "    timestamps_per_week = 24 * 7\n",
    "    samples = timestamps - timestamps_per_week - prediction_timestamps\n",
    "    print(samples)\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(samples):\n",
    "        X.append(df[i:i+timestamps_per_week].to_numpy().flatten())\n",
    "        y.append(df['main_level'].iloc[i + timestamps_per_week : \n",
    "                                       i + timestamps_per_week + prediction_timestamps : \n",
    "                                           prediction_step])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_sample_dataframe(X, index):\n",
    "    \n",
    "    assert 0 <= index <= X.shape[0]\n",
    "    \n",
    "    sample_mat = X[index].reshape((24*7,9))\n",
    "    sample_df = pd.DataFrame(sample_mat[:, 1:], index=sample_mat[:,0])\n",
    "\n",
    "    return sample_df\n",
    "\n",
    "def plot_in_2d(X, title=None):\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(X)\n",
    "    X_2d = pca.transform(X)\n",
    "    plt.scatter(X_2d[:,0], X_2d[:,1])\n",
    "    \n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.show()    \n",
    "    \n",
    "# Root Mean Square Error\n",
    "def rmse(y_pred, y_true):  \n",
    "    return np.sqrt(np.mean((y_pred - y_true)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_a.status.interpolate(method=\"pad\", inplace=True)\n",
    "station_c.status.interpolate(method=\"pad\", inplace=True)\n",
    "\n",
    "## For the numerical attributes we use linear interpolation\n",
    "station_a.temp_c.interpolate(method=\"linear\", inplace=True)\n",
    "station_c.temp_c.interpolate(method=\"linear\", inplace=True)\n",
    "\n",
    "station_a.rain_mm.interpolate(method=\"linear\", inplace=True)\n",
    "station_c.rain_mm.interpolate(method=\"linear\", inplace=True)\n",
    "\n",
    "station_main.level_cm.interpolate(method=\"linear\", inplace=True)\n",
    "station_main.flow_m3_s.interpolate(method=\"linear\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the status\n",
    "station_a.status = pd.Categorical(station_a.status, categories = [\"low\", \"decreased\", \"normal\", \"increased\", \"max\"]).codes\n",
    "station_c.status = pd.Categorical(station_c.status, categories = [\"low\", \"decreased\", \"normal\", \"increased\", \"max\"]).codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_level</th>\n",
       "      <th>main_flow</th>\n",
       "      <th>a_temp</th>\n",
       "      <th>a_status</th>\n",
       "      <th>a_rain</th>\n",
       "      <th>c_temp</th>\n",
       "      <th>c_status</th>\n",
       "      <th>c_rain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-04-06 00:00:00</th>\n",
       "      <td>161.0</td>\n",
       "      <td>4.85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-06 01:00:00</th>\n",
       "      <td>162.0</td>\n",
       "      <td>4.97</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-06 02:00:00</th>\n",
       "      <td>161.0</td>\n",
       "      <td>4.85</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-06 03:00:00</th>\n",
       "      <td>162.0</td>\n",
       "      <td>4.97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-06 04:00:00</th>\n",
       "      <td>161.0</td>\n",
       "      <td>4.85</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-12 19:00:00</th>\n",
       "      <td>169.0</td>\n",
       "      <td>5.82</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-12 20:00:00</th>\n",
       "      <td>170.0</td>\n",
       "      <td>5.95</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-12 21:00:00</th>\n",
       "      <td>170.0</td>\n",
       "      <td>5.95</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-12 22:00:00</th>\n",
       "      <td>170.5</td>\n",
       "      <td>6.07</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-12 23:00:00</th>\n",
       "      <td>171.0</td>\n",
       "      <td>6.07</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     main_level  main_flow  a_temp  a_status  a_rain  c_temp  \\\n",
       "time                                                                           \n",
       "2019-04-06 00:00:00       161.0       4.85     NaN         2     0.0     6.3   \n",
       "2019-04-06 01:00:00       162.0       4.97     4.9         2     0.0     5.6   \n",
       "2019-04-06 02:00:00       161.0       4.85     4.4         2     0.0     4.9   \n",
       "2019-04-06 03:00:00       162.0       4.97     4.0         3     0.0     4.3   \n",
       "2019-04-06 04:00:00       161.0       4.85     3.3         3     0.0     3.5   \n",
       "...                         ...        ...     ...       ...     ...     ...   \n",
       "2019-04-12 19:00:00       169.0       5.82     7.5         3     0.0     7.2   \n",
       "2019-04-12 20:00:00       170.0       5.95     7.0         3     0.0     6.8   \n",
       "2019-04-12 21:00:00       170.0       5.95     6.8         3     0.0     6.7   \n",
       "2019-04-12 22:00:00       170.5       6.07     6.4         3     0.0     6.3   \n",
       "2019-04-12 23:00:00       171.0       6.07     6.5         3     0.0     6.7   \n",
       "\n",
       "                     c_status  c_rain  \n",
       "time                                   \n",
       "2019-04-06 00:00:00         2     0.0  \n",
       "2019-04-06 01:00:00         2     0.0  \n",
       "2019-04-06 02:00:00         2     0.0  \n",
       "2019-04-06 03:00:00         2     0.0  \n",
       "2019-04-06 04:00:00         3     0.0  \n",
       "...                       ...     ...  \n",
       "2019-04-12 19:00:00         3     0.0  \n",
       "2019-04-12 20:00:00         3     0.0  \n",
       "2019-04-12 21:00:00         3     0.0  \n",
       "2019-04-12 22:00:00         3     0.0  \n",
       "2019-04-12 23:00:00         2     0.0  \n",
       "\n",
       "[168 rows x 8 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stations = station_main.join(station_a.join(station_c, how=\"inner\", rsuffix=\"_from_c\"), how=\"inner\")\n",
    "all_stations.columns = [\"main_level\", \"main_flow\", \"a_temp\", \"a_status\", \"a_rain\", \"c_temp\", \"c_status\", \"c_rain\"]\n",
    "all_stations\n",
    "# all_stations.reset_index(inplace= True)\n",
    "# all_stations.head()\n",
    "# all_stations.to_csv(file_all_station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(pd.isna(all_stations))\n",
    "all_stations.to_csv(file_all_station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X, y = create_X_y(sample_df)\n",
    "# Remove timestamps\n",
    "# X = np.delete(X, slice(0, X.shape[1], 9), axis=1)\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
